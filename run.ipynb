{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# ABOUT\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook you can see and experiment with our pretrained model\n",
    "#### The project is HEAVILY INSPIRED from Andrej Karpathy's MiniGPT implementation\n",
    "#### The lisence info can be  found in the file : LISENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# IMPORTS & SETUP\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for all modules\n",
    "from src.utils import set_seed, predict_in_a_cool_way\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.dataset import CharDataset\n",
    "from src.model import GPT, GPTConfig\n",
    "from src.trainer import Trainer, TrainerConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# MODEL\n",
    "Setup the model\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 75 unique characters with total length : 3559319 \n",
      "The data has 62 unique characters with total length : 406105 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/21/2024 19:12:44 - INFO - src.model -   number of parameters: 2.536243e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "THE MODEL IS LOADED SUCCESSFULLY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 128 # Maximum context length allowed\n",
    "\n",
    "train_text = open('./data/train.txt', 'r').read() \n",
    "test_text  = open('./data/test.txt' , 'r').read() \n",
    "\n",
    "train_dataset = CharDataset(train_text, block_size) \n",
    "test_dataset = CharDataset(test_text, block_size) \n",
    "\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)\n",
    "\n",
    "# Training Configuration & trainer_config\n",
    "trainer_config = TrainerConfig(max_epochs=5, batch_size=128, learning_rate=6e-4, lr_decay=True, warmup_tokens=512*20,       # Trainer configuration\n",
    "                               final_tokens=2*len(train_dataset)*block_size, num_workers=4, ckpt_path=None)\n",
    "\n",
    "trainer = Trainer(model=model, train_dataset=train_dataset, test_dataset=test_dataset, config =trainer_config)              # Trainer object\n",
    "\n",
    "print(\"\\nTHE MODEL IS LOADED SUCCESSFULLY\")\n",
    "model.load_state_dict(torch.load('./models/our_trained_model.pt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# INFERENCE for our model\n",
    "The best model checkpoint is saved at 'models' folder, correspontding to the specific date and time at which the model was made\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tu hi yeh mujkho bata dey tujhko.\n",
      "Haan mera yaar mujhse kusoon sa chahe.\n",
      "Dil ne jab jab mile toh maza hai.\n",
      "Jaan le tu.\n",
      "Tu hi dil mein samaya ha.\n",
      "Tune dil mera churaya hai.\n",
      "Teri palkon ki in galiyon mein sapno ki sej sajaungi.\n",
      "Tujhe dekhun, tujhe chahun, teri khushboo mein kho gaye.\n",
      "Jaanejaana ... ho jaanejaan.\n",
      "O jaanejaan ... O jaanejaan.\n",
      "Ho milenge do deewane.\n",
      "Banenge phir afsane.\n",
      "Karega apna charcha yeh jahaan.\n",
      "Dhin dhinak dhin.\n",
      "Dhinak dhin dhin dhinak dhin.\n",
      "Dhinak dhin dhin dhinak dhin.\n",
      "Dhinak dhin dhin dhinak dhin, dhinak dhin.\n",
      "Nisha ... Nisha ... Nisha ... Nisha... Nisha.\n",
      "Ishaq mein tum sabko main sikha doon aur waqt waqt.\n",
      "Tum jiyo ka dastoor tamaam.\n",
      "Chaal hai bairi Shiv Shankar ki jai.\n",
      "Ho jaaye jeena tere sibah.\n",
      "Ho jaaye jeena tere sibah.\n",
      "Ho ho ho jaaye jeena tere sibah.\n",
      "Bebasi ka maza aa gaya.\n",
      "Jaane kyun a"
     ]
    }
   ],
   "source": [
    "# Please enter the context for the lyric generation, you can also change the output length below\n",
    "context = 'Tu hi yeh mujkho bata dey'\n",
    "\n",
    "predict_in_a_cool_way(context=context, train_dataset=train_dataset, model=model, trainer=trainer, output_len=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________\n",
    "# <center>THANK YOU</center>\n",
    "_________________________________\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
