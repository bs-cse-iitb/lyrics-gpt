{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# ABOUT\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this project we train a Transformer decoder type model with masked attention at Charater Level.  After training the model generates new lyrics for songs, given the initial sentence\n",
    "#### The project is HEAVILY INSPIRED from Andrej Karpathy's MiniGPT implementation\n",
    "#### The lisence info can be  found in the file : LISENCE\n",
    "#### Lets begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# IMPORTS & SETUP\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "# Set seeds for all modules\n",
    "from src.utils import set_seed, current_moment, predict_in_a_cool_way\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.dataset import CharDataset\n",
    "from src.model import GPT, GPTConfig\n",
    "from src.trainer import Trainer, TrainerConfig\n",
    "\n",
    "block_size = 128 # Maximum context length allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# DATASET\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA is stored at <data> folder, test/train ratio 1:9\n",
    "# You can change <tiny> flag to True in order to do test runs on a very small subset of the data \n",
    "\n",
    "tiny = True        # Set this flag True for small data subset\n",
    "\n",
    "if tiny:\n",
    "    train_text = open('./data/train_tiny.txt', 'r').read() \n",
    "    test_text  = open('./data/test_tiny.txt' , 'r').read() \n",
    "else:\n",
    "    train_text = open('./data/train.txt', 'r').read() \n",
    "    test_text  = open('./data/test.txt' , 'r').read() \n",
    "\n",
    "train_dataset = CharDataset(train_text, block_size) \n",
    "test_dataset = CharDataset(test_text, block_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# MODEL\n",
    "Instatntiate the model. Feel free to change the number of layer and heads below\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# TRAINING\n",
    "\n",
    "Now we train the model. Feel free to change the trainer configuration below according to your choice\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration & trainer_config\n",
    "trained_model_path = './models/'  + current_moment() + '_best.ckpt'         # The trained model is saved in <models> folder\n",
    "trainer_config = TrainerConfig(max_epochs=5, batch_size=128, learning_rate=6e-4, lr_decay=True, warmup_tokens=512*20,       # Trainer configuration\n",
    "                               final_tokens=2*len(train_dataset)*block_size, num_workers=4, ckpt_path=trained_model_path)\n",
    "\n",
    "trainer = Trainer(model=model, train_dataset=train_dataset, test_dataset=test_dataset, config =trainer_config)              # Trainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "# INFERENCE for the above trained model\n",
    "The best model checkpoint is saved at 'models' folder, correspontding to the specific date and time at which the model was made\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrained_model_path\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_model_path' is not defined"
     ]
    }
   ],
   "source": [
    "print(trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "checkpoint = torch.load(trained_model_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please enter the context for the lyric generation, you can also change the output length below\n",
    "context = 'Tu hi meri shab hai subah hai tu hi din hai mera'\n",
    "\n",
    "predict_in_a_cool_way(context=context, train_dataset=train_dataset, model=model, trainer=trainer, output_len=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________\n",
    "# <center>THANK YOU</center>\n",
    "_________________________________\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
